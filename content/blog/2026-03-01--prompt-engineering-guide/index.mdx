---
title: 大模型 Prompt 技巧全解析
slug: prompt-engineering-guide
description: 深入探讨 Prompt 的定义、撰写框架、核心原则以及多种高级技术，助力更好地运用大模型提升业务价值。
date: 2026-03-01
lastUpdated: 2026-03-01
tags:
  - Tutorial
  - Softwares
searchIndex: true
---

:::note[引用说明]
本文基于 mitin 的文章整理与延展：[大模型Prompt技巧全解析](https://mp.weixin.qq.com/s/u-79q3R0l01oO-7WWUNF2A)。
:::

## 什么是 Prompt

在大语言模型应用中，Prompt 是用于"提示"模型唤起特定能力以解决实际问题的提问方式。早期它被称作"输入形式"或"输入模板"，后来因为"Prompt"这个叫法更契合大语言模型语境，能准确体现其在调用模型能力方面的关键作用，成为公认术语。

大模型的核心能力在预训练阶段已经形成，Prompt 就像一把钥匙，引导模型从预训练积累的海量信息中，精准唤起如理解复杂文本、总结信息、生成内容、逻辑推理等能力，满足用户实际需求。

它不是把模型当作单纯的知识库，而是高效调用其能力，实现类似人类运用智能解决复杂问题的效果。这正是 Prompt 工程的核心，对用好大语言模型意义重大。

## Prompt 的基本框架

### 包含的要素

- **指令**：想要模型执行的特定任务或指令
- **上下文**：包含外部信息或额外的上下文信息，引导语言模型更好地响应
- **输入数据**：用户输入的内容或问题
- **输出指示**：指定输出的类型或格式

### 五大框架

#### RTF 框架

RTF（Role-Task-Format）是一个非常简单通用的 Prompt 提示框架：

- **R-Role（角色）**：指定大模型担当固定角色（程序员、数据分析师、讲解员等）
- **T-Task（任务）**：告诉大模型需要为我们做的事情
- **F-Format（格式）**：大模型最终结果的返回格式（如表格、Markdown、英文等）

**主要优点**：
- 简单、方便
- 指定 Role 可以让大模型在当前角色范围内回答知识，特定领域非常有效
- 如果结合 RAG 知识内容检索，上下文回答的内容会更加顺畅

#### 思考链模式

通过在 Prompt 末尾添加"让我们逐步思考"，可以逐步改善大模型的推理能力，非常适合：

- 分析型或逻辑推理型的任务
- 决策
- 解决问题（比如程序员根据错误日志找 Bug）

例如：

```python
# 没有思考链
prompt1 = "分析一下在人工客服服务场景下，XXX中客户有哪些诉求。用一句话概括。"
# 输出：客户主要诉求为：微信账号存在安全风险导致无法添加好友、单点拦截...

# 有思考链
prompt2 = "分析一下在人工客服服务场景下，XXX中客户有哪些诉求。用一句话概括。让我们逐步思考。"
# 输出：客户主要诉求为：微信账号存在安全风险导致无法添加好友，以及因违规行为被限制登录...
```

显然，使用思考链后，模型的分析更加准确。

#### RISEN 框架

- **R-Role**：大模型扮演的角色
- **I-Instructions**：指示命令，和 Task 差不多
- **S-Steps**：步骤
- **E-End Goal**：最终目标
- **N-Narrowing（Constraints）**：缩小范围（约束条件）

适合撰写具有特定约束的任务（如博客文章）或有明确指导方针的任务（如商业计划）。

#### RODES 框架

- **R-Role**：角色
- **O-Objective**：目标
- **D-Details**：详细的细节
- **E-Examples**：示例
- **S-Sense Check**：感官检查

#### 密度链模式

密度链模式是 Salesforce、麻省理工学院和哥伦比亚大学的研究人员推出的一种新提示技术，使用递归来创建越来越好的输出。与普通 Prompt 生成的 GPT-4 摘要相比，它生成的摘要更加密集且更适合人们理解。

适合：
- 总结
- 改进你喜欢的提示
- 通过递归生成可用的长格式内容

## 打造高效 Prompt 的两大核心原则

### 原则一：编写明确和具体的指令

#### 策略 1：使用分隔符清晰界定输入部分

在构建 Prompt 时，使用分隔符将特定文本部分与提示的其他部分清晰隔开，能有效避免提示词冲突。常见分隔符包括：

- 章节标题：通过不同层级的标题区分不同内容模块
- 三重双引号：`"""`
- 三重单引号：`'''`
- 三重破折号：`---`
- 角括号：`<>`
- XML 标签：`<text></text>`

#### 策略 2：要求结构化输出

为了便于后续对模型输出进行解析和处理，我们可以要求模型以特定的结构化格式输出，如 HTML 或 JSON。

示例：要求模型以 JSON 格式输出

```python
prompt = "请以json格式列出每个nodeType所体现的用户诉求、客服方案。"
```

#### 策略 3：要求模型检查条件是否满足

在面对复杂任务时，如果在一些假设条件下，而这些条件并非总是成立，那么我们需要引导模型首先对这些假设进行检查。

示例：计算数学表达式，前提是所有数字都为正数

```python
expression = "5 + 3 - (-2)"
prompt = f"首先检查表达式 '{expression}' 中的所有数字是否都为正数。"
```

#### 策略 4：Few-shot Prompting（少样本提示）

在要求模型执行任务时，提供成功完成任务的示例，能够帮助模型更好地理解任务要求和期望输出的格式。

### 原则二：给予模型充足的思考时间

#### 策略 1：明确完成任务所需的步骤

为模型详细指定完成任务所需遵循的步骤，能够帮助模型有条不紊地推理和计算。

#### 策略 2：引导模型在得出结论前充分思考方案

明确指示模型在得出最终结论前，先进行充分的推理和分析，往往能获得更优的结果。

## 模型的局限性与应对策略

### 模型"幻觉"

即使模型在训练过程中接触了海量知识，但它并不能完美记住所有信息，也难以精准把握自身知识的边界。这就导致在面对晦涩主题的问题时，模型可能会编造出看似合理但实际上错误的内容，这就是所谓的"幻觉"。

### 解决幻觉的一种策略

为了有效应对幻觉问题，我们可以要求模型在回答问题前，首先从给定文本中寻找相关引用，并依据这些引用来构建答案。

## Prompt 技术剖析与应用

### 零样本提示（Zero-Shot Prompting）

零样本提示是一种让模型在没有特定任务示例展示的情况下直接处理任务的技术。由于缺乏具体示例引导，对于复杂任务，其效果可能受限。

### 少样本提示（Few-Shot Prompting）

少样本提示通过为模型提供少量任务示例，帮助模型学习任务模式和规律。

### 思维链提示（Chain-of-Thought Prompting）

思维链提示旨在为模型提供清晰的推理步骤引导，从而显著提升其在复杂推理任务中的表现。

### 检索增强生成（RAG）

检索增强生成（RAG）技术将信息检索与文本生成相结合，专门用于处理知识密集型任务。它通过检索相关文档来为模型提供额外的知识支持，从而缓解模型的"幻觉"问题。

### 链式提示（Prompt Chaining）

链式提示是将复杂任务拆解为多个子任务，通过逐个子任务生成提示并传递结果的方式来实现复杂任务的有序处理。

### ReAct 框架

ReAct 框架使模型交错生成推理轨迹和操作，提升答案的可靠性与可解释性。

## 总结

Prompt 工程是释放大语言模型强大潜力的关键。通过掌握基本框架、核心原则和高级技术，我们可以：

1. **编写明确具体的指令**，避免模型产生误解
2. **给予模型充足的思考时间**，引导其进行深入推理
3. **运用合适的框架**（如 RTF、RISEN）来规范 Prompt 结构
4. **使用高级技术**（如思维链、RAG、ReAct）来应对复杂任务
5. **应对模型局限性**，通过引用和结构化输出减少"幻觉"

无论是在客服托管、智能客服等实际业务场景，还是在个人学习和开发中，精心设计的 Prompt 都能让大模型发挥更大的价值，大幅提高工作效率，优化成果质量。

:::tip
最好的学习方式是实践。选择一个你关心的任务，尝试运用本文介绍的方法来优化你的 Prompt，观察模型输出的变化，逐步积累经验。
:::
